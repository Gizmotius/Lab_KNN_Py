# Лабораторная работа: KNN классификатор

## Автор
Шаронов Артем

## Описание
Данная лабораторная работа посвящена исследованию классификатора "метод поиска ближайших соседей" на различных наборах данных с использованием Jupyter Notebook.

## Содержание
1. [Задание 1](#задание-1)
2. [Задание 2](#задание-2)
3. [Задание 3](#задание-3)
5. [Задание 4](#задание-4)

## Задание 1 

Исследуйте, как объем обучающей выборки и количество тестовых данных влияет на точность классификации или на вероятность ошибочной классификации в примере крестики-нолики и примере о спаме e-mail сообщений.

## Задание 2 

Постройте классификатор для обучающего множества Glass, данные которого характеризуются 10 признаками:
1. Id number: 1 to 214
2. RI: показатель преломления
3. Na: сода (процент содержания в соответствующем оксиде)
4. Mg
5. Al
6. Si
7. K
8. Ca
9. Ba
10. Fe

Классы характеризуют тип стекла:
- (1) окна зданий, плавильная обработка
- (2) окна зданий, не плавильная обработка
- (3) автомобильные окна, плавильная обработка
- (4) автомобильные окна, не плавильная обработка (нет в базе)
- (5) контейнеры
- (6) посуда
- (7) фары

Посмотрите заголовки признаков и классов. Перед построением классификатора необходимо также удалить первый признак Id number, который не несет никакой информационной нагрузки. Это выполняется командой:
```r
glass <- glass[,-1]
```
Постройте графики зависимости ошибки классификации от значения k и от типа ядра. 
Исследуйте, как тип метрики расстояния (параметр distance) влияет на точность классификации.
Определите, к какому типу стекла относится экземпляр с характеристиками:
- RI = 1.516 
- Na = 11.7 
- Mg = 1.01
-  Al = 1.19
-  Si = 72.59 
- K = 0.43 
- Ca = 11.44 
- Ba = 0.02 
- Fe = 0.1

Определите, какой из признаков оказывает наименьшее влияние на определение класса путем 
последовательного исключения каждого признака.

## Задание 3

Для построения классификатора используйте заранее сгенерированные обучающие и тестовые 
выборки, хранящиеся в файлах svmdata4.txt, svmdata4test.txt. Найдите оптимальное значение k, 
обеспечивающее наименьшую ошибку классификации. Посмотрите, как выглядят данные на
графике, используя функцию:

```r
plot(mydata.train$X1, mydata.train$X2, pch=21, bg=c("red","blue") 
[unclass(mydata.train$Colors)], main="My train data")
```
## Задание 4

Разработать классификатор на основе метода ближайших соседей для данных Титаник
(Titanic dataset) - https://www.kaggle.com/c/titanic